// Copyright (c) 2018-2020, NVIDIA CORPORATION. All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions
// are met:
//  * Redistributions of source code must retain the above copyright
//    notice, this list of conditions and the following disclaimer.
//  * Redistributions in binary form must reproduce the above copyright
//    notice, this list of conditions and the following disclaimer in the
//    documentation and/or other materials provided with the distribution.
//  * Neither the name of NVIDIA CORPORATION nor the names of its
//    contributors may be used to endorse or promote products derived
//    from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
// EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
// PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
// CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
// EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
// PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
// OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.21.0-devel
// 	protoc        (unknown)
// source: api.proto

package nvidia_inferenceserver

import (
	proto "github.com/golang/protobuf/proto"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// This is a compile-time assertion that a sufficiently up-to-date version
// of the legacy proto package is being used.
const _ = proto.ProtoPackageIsVersion4

//@@  .. cpp:enum:: Flag
//@@
//@@     Flags that can be associated with an inference request.
//@@     All flags are packed bitwise into the 'flags' field and
//@@     so the value of each must be a power-of-2.
//@@
type InferRequestHeader_Flag int32

const (
	//@@    .. cpp:enumerator:: Flag::FLAG_NONE = 0
	//@@
	//@@       Value indicating no flags are enabled.
	//@@
	InferRequestHeader_FLAG_NONE InferRequestHeader_Flag = 0
	//@@    .. cpp:enumerator:: Flag::FLAG_SEQUENCE_START = 1 << 0
	//@@
	//@@       This request is the start of a related sequence of requests.
	//@@
	InferRequestHeader_FLAG_SEQUENCE_START InferRequestHeader_Flag = 1
	//@@    .. cpp:enumerator:: Flag::FLAG_SEQUENCE_END = 1 << 1
	//@@
	//@@       This request is the end of a related sequence of requests.
	//@@
	InferRequestHeader_FLAG_SEQUENCE_END InferRequestHeader_Flag = 2
)

// Enum value maps for InferRequestHeader_Flag.
var (
	InferRequestHeader_Flag_name = map[int32]string{
		0: "FLAG_NONE",
		1: "FLAG_SEQUENCE_START",
		2: "FLAG_SEQUENCE_END",
	}
	InferRequestHeader_Flag_value = map[string]int32{
		"FLAG_NONE":           0,
		"FLAG_SEQUENCE_START": 1,
		"FLAG_SEQUENCE_END":   2,
	}
)

func (x InferRequestHeader_Flag) Enum() *InferRequestHeader_Flag {
	p := new(InferRequestHeader_Flag)
	*p = x
	return p
}

func (x InferRequestHeader_Flag) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (InferRequestHeader_Flag) Descriptor() protoreflect.EnumDescriptor {
	return file_api_proto_enumTypes[0].Descriptor()
}

func (InferRequestHeader_Flag) Type() protoreflect.EnumType {
	return &file_api_proto_enumTypes[0]
}

func (x InferRequestHeader_Flag) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use InferRequestHeader_Flag.Descriptor instead.
func (InferRequestHeader_Flag) EnumDescriptor() ([]byte, []int) {
	return file_api_proto_rawDescGZIP(), []int{1, 0}
}

//@@.. cpp:var:: message InferSharedMemory
//@@
//@@   The meta-data for the shared memory from which to read the input
//@@   data and/or write the output data.
//@@
type InferSharedMemory struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	//@@  .. cpp:var:: string name
	//@@
	//@@     The name given during registration of a shared memory region that
	//@@     holds the input data (or where the output data should be written).
	//@@
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	//@@  .. cpp:var:: uint64 offset
	//@@
	//@@     The offset from the start of the shared memory region.
	//@@     start = offset, end = offset + size;
	//@@
	Offset uint64 `protobuf:"varint,2,opt,name=offset,proto3" json:"offset,omitempty"`
	//@@  .. cpp:var:: uint64 byte_size
	//@@
	//@@     Size of the memory block, in bytes.
	//@@
	ByteSize uint64 `protobuf:"varint,3,opt,name=byte_size,json=byteSize,proto3" json:"byte_size,omitempty"`
}

func (x *InferSharedMemory) Reset() {
	*x = InferSharedMemory{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_proto_msgTypes[0]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *InferSharedMemory) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferSharedMemory) ProtoMessage() {}

func (x *InferSharedMemory) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_msgTypes[0]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferSharedMemory.ProtoReflect.Descriptor instead.
func (*InferSharedMemory) Descriptor() ([]byte, []int) {
	return file_api_proto_rawDescGZIP(), []int{0}
}

func (x *InferSharedMemory) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *InferSharedMemory) GetOffset() uint64 {
	if x != nil {
		return x.Offset
	}
	return 0
}

func (x *InferSharedMemory) GetByteSize() uint64 {
	if x != nil {
		return x.ByteSize
	}
	return 0
}

//@@
//@@.. cpp:var:: message InferRequestHeader
//@@
//@@   Meta-data for an inferencing request. The actual input data is
//@@   delivered separate from this header, in the HTTP body for an HTTP
//@@   request, or in the :cpp:var:`InferRequest` message for a gRPC request.
//@@
type InferRequestHeader struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	//@@  .. cpp:var:: uint64 id
	//@@
	//@@     The ID of the inference request. The response of the request will
	//@@     have the same ID in InferResponseHeader. The request sender can use
	//@@     the ID to correlate the response to corresponding request if needed.
	//@@
	Id uint64 `protobuf:"varint,5,opt,name=id,proto3" json:"id,omitempty"`
	//@@  .. cpp:var:: uint32 flags
	//@@
	//@@     The flags associated with this request. This field holds a bitwise-or
	//@@     of all flag values.
	//@@
	Flags uint32 `protobuf:"varint,6,opt,name=flags,proto3" json:"flags,omitempty"`
	//@@  .. cpp:var:: uint64 correlation_id
	//@@
	//@@     The correlation ID of the inference request. Default is 0, which
	//@@     indictes that the request has no correlation ID. The correlation ID
	//@@     is used to indicate two or more inference request are related to
	//@@     each other. How this relationship is handled by the inference
	//@@     server is determined by the model's scheduling policy.
	//@@
	CorrelationId uint64 `protobuf:"varint,4,opt,name=correlation_id,json=correlationId,proto3" json:"correlation_id,omitempty"`
	//@@  .. cpp:var:: uint32 batch_size
	//@@
	//@@     The batch size of the inference request. This must be >= 1. For
	//@@     models that don't support batching, batch_size must be 1.
	//@@
	BatchSize uint32 `protobuf:"varint,1,opt,name=batch_size,json=batchSize,proto3" json:"batch_size,omitempty"`
	//@@  .. cpp:var:: Input input (repeated)
	//@@
	//@@     The input meta-data for the inputs provided with the the inference
	//@@     request.
	//@@
	Input []*InferRequestHeader_Input `protobuf:"bytes,2,rep,name=input,proto3" json:"input,omitempty"`
	//@@  .. cpp:var:: Output output (repeated)
	//@@
	//@@     The output meta-data for the inputs provided with the the inference
	//@@     request.
	//@@
	Output []*InferRequestHeader_Output `protobuf:"bytes,3,rep,name=output,proto3" json:"output,omitempty"`
	//@@  .. cpp:var:: uint32 priority
	//@@
	//@@     The priority value of this request. If priority handling is not
	//@@     enable for the model, then this value is ignored. The default value
	//@@     is 0 which indicates that the request will be assigned the default
	//@@     priority associated with the model.
	//@@
	Priority uint32 `protobuf:"varint,7,opt,name=priority,proto3" json:"priority,omitempty"`
	//@@  .. cpp:var:: uint64 timeout_microseconds
	//@@
	//@@     The timeout for this request. This value overrides the timeout
	//@@     specified by the model, if the model allows timeout override and if
	//@@     the value is less than the default timeout specified by the model.
	//@@     If the request cannot be processed within this timeout, the request
	//@@     will be handled based on the model's timeout policy.
	//@@     Note that request for ensemble model cannot override the timeout
	//@@     values for the composing models.
	//@@     The default value is 0 which indicates that the request does not
	//@@     override the model's timeout value.
	//@@
	TimeoutMicroseconds uint64 `protobuf:"varint,8,opt,name=timeout_microseconds,json=timeoutMicroseconds,proto3" json:"timeout_microseconds,omitempty"`
}

func (x *InferRequestHeader) Reset() {
	*x = InferRequestHeader{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_proto_msgTypes[1]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *InferRequestHeader) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferRequestHeader) ProtoMessage() {}

func (x *InferRequestHeader) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_msgTypes[1]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferRequestHeader.ProtoReflect.Descriptor instead.
func (*InferRequestHeader) Descriptor() ([]byte, []int) {
	return file_api_proto_rawDescGZIP(), []int{1}
}

func (x *InferRequestHeader) GetId() uint64 {
	if x != nil {
		return x.Id
	}
	return 0
}

func (x *InferRequestHeader) GetFlags() uint32 {
	if x != nil {
		return x.Flags
	}
	return 0
}

func (x *InferRequestHeader) GetCorrelationId() uint64 {
	if x != nil {
		return x.CorrelationId
	}
	return 0
}

func (x *InferRequestHeader) GetBatchSize() uint32 {
	if x != nil {
		return x.BatchSize
	}
	return 0
}

func (x *InferRequestHeader) GetInput() []*InferRequestHeader_Input {
	if x != nil {
		return x.Input
	}
	return nil
}

func (x *InferRequestHeader) GetOutput() []*InferRequestHeader_Output {
	if x != nil {
		return x.Output
	}
	return nil
}

func (x *InferRequestHeader) GetPriority() uint32 {
	if x != nil {
		return x.Priority
	}
	return 0
}

func (x *InferRequestHeader) GetTimeoutMicroseconds() uint64 {
	if x != nil {
		return x.TimeoutMicroseconds
	}
	return 0
}

//@@
//@@.. cpp:var:: message InferResponseHeader
//@@
//@@   Meta-data for the response to an inferencing request. The actual output
//@@   data is delivered separate from this header, in the HTTP body for an HTTP
//@@   request, or in the :cpp:var:`InferResponse` message for a gRPC request.
//@@
type InferResponseHeader struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	//@@  .. cpp:var:: uint64 id
	//@@
	//@@     The ID of the inference response. The response will have the same ID
	//@@     as the ID of its originated request. The request sender can use
	//@@     the ID to correlate the response to corresponding request if needed.
	//@@
	Id uint64 `protobuf:"varint,5,opt,name=id,proto3" json:"id,omitempty"`
	//@@  .. cpp:var:: string model_name
	//@@
	//@@     The name of the model that produced the outputs.
	//@@
	ModelName string `protobuf:"bytes,1,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`
	//@@  .. cpp:var:: int64 model_version
	//@@
	//@@     The version of the model that produced the outputs.
	//@@
	ModelVersion int64 `protobuf:"varint,2,opt,name=model_version,json=modelVersion,proto3" json:"model_version,omitempty"`
	//@@  .. cpp:var:: uint32 batch_size
	//@@
	//@@     The batch size of the outputs. This will always be equal to the
	//@@     batch size of the inputs. For models that don't support
	//@@     batching the batch_size will be 1.
	//@@
	BatchSize uint32 `protobuf:"varint,3,opt,name=batch_size,json=batchSize,proto3" json:"batch_size,omitempty"`
	//@@  .. cpp:var:: Output output (repeated)
	//@@
	//@@     The outputs, in the same order as they were requested in
	//@@     :cpp:var:`InferRequestHeader`.
	//@@
	Output []*InferResponseHeader_Output `protobuf:"bytes,4,rep,name=output,proto3" json:"output,omitempty"`
}

func (x *InferResponseHeader) Reset() {
	*x = InferResponseHeader{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_proto_msgTypes[2]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *InferResponseHeader) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferResponseHeader) ProtoMessage() {}

func (x *InferResponseHeader) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_msgTypes[2]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferResponseHeader.ProtoReflect.Descriptor instead.
func (*InferResponseHeader) Descriptor() ([]byte, []int) {
	return file_api_proto_rawDescGZIP(), []int{2}
}

func (x *InferResponseHeader) GetId() uint64 {
	if x != nil {
		return x.Id
	}
	return 0
}

func (x *InferResponseHeader) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

func (x *InferResponseHeader) GetModelVersion() int64 {
	if x != nil {
		return x.ModelVersion
	}
	return 0
}

func (x *InferResponseHeader) GetBatchSize() uint32 {
	if x != nil {
		return x.BatchSize
	}
	return 0
}

func (x *InferResponseHeader) GetOutput() []*InferResponseHeader_Output {
	if x != nil {
		return x.Output
	}
	return nil
}

//@@  .. cpp:var:: message Input
//@@
//@@     Meta-data for an input tensor provided as part of an inferencing
//@@     request.
//@@
type InferRequestHeader_Input struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	//@@    .. cpp:var:: string name
	//@@
	//@@       The name of the input tensor.
	//@@
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	//@@    .. cpp:var:: int64 dims (repeated)
	//@@
	//@@       The shape of the input tensor, not including the batch dimension.
	//@@       Optional if the model configuration for this input explicitly
	//@@       specifies all dimensions of the shape. Required if the model
	//@@       configuration for this input has any wildcard dimensions (-1).
	//@@
	Dims []int64 `protobuf:"varint,2,rep,packed,name=dims,proto3" json:"dims,omitempty"`
	//@@    .. cpp:var:: uint64 batch_byte_size
	//@@
	//@@       The size of the full batch of the input tensor, in bytes.
	//@@       Optional for tensors with fixed-sized datatypes. Required
	//@@       for tensors with a non-fixed-size datatype (like STRING).
	//@@
	BatchByteSize uint64 `protobuf:"varint,3,opt,name=batch_byte_size,json=batchByteSize,proto3" json:"batch_byte_size,omitempty"`
	//@@    .. cpp:var:: InferSharedMemory shared_memory
	//@@
	//@@       It is the location in shared memory that contains the tensor data
	//@@       for this input. Using shared memory is optional but if this
	//@@       message is used, all fields are required.
	//@@
	SharedMemory *InferSharedMemory `protobuf:"bytes,4,opt,name=shared_memory,json=sharedMemory,proto3" json:"shared_memory,omitempty"`
}

func (x *InferRequestHeader_Input) Reset() {
	*x = InferRequestHeader_Input{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_proto_msgTypes[3]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *InferRequestHeader_Input) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferRequestHeader_Input) ProtoMessage() {}

func (x *InferRequestHeader_Input) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_msgTypes[3]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferRequestHeader_Input.ProtoReflect.Descriptor instead.
func (*InferRequestHeader_Input) Descriptor() ([]byte, []int) {
	return file_api_proto_rawDescGZIP(), []int{1, 0}
}

func (x *InferRequestHeader_Input) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *InferRequestHeader_Input) GetDims() []int64 {
	if x != nil {
		return x.Dims
	}
	return nil
}

func (x *InferRequestHeader_Input) GetBatchByteSize() uint64 {
	if x != nil {
		return x.BatchByteSize
	}
	return 0
}

func (x *InferRequestHeader_Input) GetSharedMemory() *InferSharedMemory {
	if x != nil {
		return x.SharedMemory
	}
	return nil
}

//@@  .. cpp:var:: message Output
//@@
//@@     Meta-data for a requested output tensor as part of an inferencing
//@@     request.
//@@
type InferRequestHeader_Output struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	//@@    .. cpp:var:: string name
	//@@
	//@@       The name of the output tensor.
	//@@
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	//@@    .. cpp:var:: Class cls
	//@@
	//@@       Optional. If defined return this output as a classification
	//@@       instead of raw data. The output tensor will be interpreted as
	//@@       probabilities and the classifications associated with the
	//@@       highest probabilities will be returned.
	//@@
	Cls *InferRequestHeader_Output_Class `protobuf:"bytes,3,opt,name=cls,proto3" json:"cls,omitempty"`
	//@@    .. cpp:var:: InferSharedMemory shared_memory
	//@@
	//@@       It is the location in shared memory that the result tensor data
	//@@       for this output will be written. Using shared memory is optional
	//@@       but if this message is used, all fields are required.
	//@@
	SharedMemory *InferSharedMemory `protobuf:"bytes,4,opt,name=shared_memory,json=sharedMemory,proto3" json:"shared_memory,omitempty"`
}

func (x *InferRequestHeader_Output) Reset() {
	*x = InferRequestHeader_Output{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_proto_msgTypes[4]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *InferRequestHeader_Output) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferRequestHeader_Output) ProtoMessage() {}

func (x *InferRequestHeader_Output) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_msgTypes[4]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferRequestHeader_Output.ProtoReflect.Descriptor instead.
func (*InferRequestHeader_Output) Descriptor() ([]byte, []int) {
	return file_api_proto_rawDescGZIP(), []int{1, 1}
}

func (x *InferRequestHeader_Output) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *InferRequestHeader_Output) GetCls() *InferRequestHeader_Output_Class {
	if x != nil {
		return x.Cls
	}
	return nil
}

func (x *InferRequestHeader_Output) GetSharedMemory() *InferSharedMemory {
	if x != nil {
		return x.SharedMemory
	}
	return nil
}

//@@    .. cpp:var:: message Class
//@@
//@@       Options for an output returned as a classification.
//@@
type InferRequestHeader_Output_Class struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	//@@      .. cpp:var:: uint32 count
	//@@
	//@@         Indicates how many classification values should be returned
	//@@         for the output. The 'count' highest priority values are
	//@@         returned.
	//@@
	Count uint32 `protobuf:"varint,1,opt,name=count,proto3" json:"count,omitempty"`
}

func (x *InferRequestHeader_Output_Class) Reset() {
	*x = InferRequestHeader_Output_Class{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_proto_msgTypes[5]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *InferRequestHeader_Output_Class) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferRequestHeader_Output_Class) ProtoMessage() {}

func (x *InferRequestHeader_Output_Class) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_msgTypes[5]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferRequestHeader_Output_Class.ProtoReflect.Descriptor instead.
func (*InferRequestHeader_Output_Class) Descriptor() ([]byte, []int) {
	return file_api_proto_rawDescGZIP(), []int{1, 1, 0}
}

func (x *InferRequestHeader_Output_Class) GetCount() uint32 {
	if x != nil {
		return x.Count
	}
	return 0
}

//@@  .. cpp:var:: message Output
//@@
//@@     Meta-data for an output tensor requested as part of an inferencing
//@@     request.
//@@
type InferResponseHeader_Output struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	//@@    .. cpp:var:: string name
	//@@
	//@@       The name of the output tensor.
	//@@
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	//@@    .. cpp:var:: DataType data_type
	//@@
	//@@       The datatype of the output tensor.
	//@@
	DataType DataType `protobuf:"varint,4,opt,name=data_type,json=dataType,proto3,enum=nvidia.inferenceserver.DataType" json:"data_type,omitempty"`
	//@@    .. cpp:var:: Raw raw
	//@@
	//@@       If specified deliver results for this output as raw tensor data.
	//@@       The actual output data is delivered in the HTTP body for an HTTP
	//@@       request, or in the :cpp:var:`InferResponse` message for a gRPC
	//@@       request. Only one of 'raw' and 'batch_classes' may be specified.
	//@@
	Raw *InferResponseHeader_Output_Raw `protobuf:"bytes,2,opt,name=raw,proto3" json:"raw,omitempty"`
	//@@    .. cpp:var:: Classes batch_classes (repeated)
	//@@
	//@@       If specified deliver results for this output as classifications.
	//@@       There is one :cpp:var:`Classes` object for each batch entry in
	//@@       the output. Only one of 'raw' and 'batch_classes' may be
	//@@       specified.
	//@@
	BatchClasses []*InferResponseHeader_Output_Classes `protobuf:"bytes,3,rep,name=batch_classes,json=batchClasses,proto3" json:"batch_classes,omitempty"`
}

func (x *InferResponseHeader_Output) Reset() {
	*x = InferResponseHeader_Output{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_proto_msgTypes[6]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *InferResponseHeader_Output) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferResponseHeader_Output) ProtoMessage() {}

func (x *InferResponseHeader_Output) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_msgTypes[6]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferResponseHeader_Output.ProtoReflect.Descriptor instead.
func (*InferResponseHeader_Output) Descriptor() ([]byte, []int) {
	return file_api_proto_rawDescGZIP(), []int{2, 0}
}

func (x *InferResponseHeader_Output) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *InferResponseHeader_Output) GetDataType() DataType {
	if x != nil {
		return x.DataType
	}
	return DataType_TYPE_INVALID
}

func (x *InferResponseHeader_Output) GetRaw() *InferResponseHeader_Output_Raw {
	if x != nil {
		return x.Raw
	}
	return nil
}

func (x *InferResponseHeader_Output) GetBatchClasses() []*InferResponseHeader_Output_Classes {
	if x != nil {
		return x.BatchClasses
	}
	return nil
}

//@@    .. cpp:var:: message Raw
//@@
//@@       Meta-data for an output tensor being returned as raw data.
//@@
type InferResponseHeader_Output_Raw struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	//@@      .. cpp:var:: int64 dims (repeated)
	//@@
	//@@         The shape of the output tensor, not including the batch
	//@@         dimension.
	//@@
	Dims []int64 `protobuf:"varint,1,rep,packed,name=dims,proto3" json:"dims,omitempty"`
	//@@      .. cpp:var:: uint64 batch_byte_size
	//@@
	//@@         The full size of the output tensor, in bytes. For a
	//@@         batch output, this is the size of the entire batch.
	//@@
	BatchByteSize uint64 `protobuf:"varint,2,opt,name=batch_byte_size,json=batchByteSize,proto3" json:"batch_byte_size,omitempty"`
}

func (x *InferResponseHeader_Output_Raw) Reset() {
	*x = InferResponseHeader_Output_Raw{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_proto_msgTypes[7]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *InferResponseHeader_Output_Raw) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferResponseHeader_Output_Raw) ProtoMessage() {}

func (x *InferResponseHeader_Output_Raw) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_msgTypes[7]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferResponseHeader_Output_Raw.ProtoReflect.Descriptor instead.
func (*InferResponseHeader_Output_Raw) Descriptor() ([]byte, []int) {
	return file_api_proto_rawDescGZIP(), []int{2, 0, 0}
}

func (x *InferResponseHeader_Output_Raw) GetDims() []int64 {
	if x != nil {
		return x.Dims
	}
	return nil
}

func (x *InferResponseHeader_Output_Raw) GetBatchByteSize() uint64 {
	if x != nil {
		return x.BatchByteSize
	}
	return 0
}

//@@    .. cpp:var:: message Class
//@@
//@@       Information about each classification for this output.
//@@
type InferResponseHeader_Output_Class struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	//@@      .. cpp:var:: int32 idx
	//@@
	//@@         The classification index.
	//@@
	Idx int32 `protobuf:"varint,1,opt,name=idx,proto3" json:"idx,omitempty"`
	//@@      .. cpp:var:: float value
	//@@
	//@@         The classification value as a float (typically a
	//@@         probability).
	//@@
	Value float32 `protobuf:"fixed32,2,opt,name=value,proto3" json:"value,omitempty"`
	//@@      .. cpp:var:: string label
	//@@
	//@@         The label for the class (optional, only available if provided
	//@@         by the model).
	//@@
	Label string `protobuf:"bytes,3,opt,name=label,proto3" json:"label,omitempty"`
}

func (x *InferResponseHeader_Output_Class) Reset() {
	*x = InferResponseHeader_Output_Class{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_proto_msgTypes[8]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *InferResponseHeader_Output_Class) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferResponseHeader_Output_Class) ProtoMessage() {}

func (x *InferResponseHeader_Output_Class) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_msgTypes[8]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferResponseHeader_Output_Class.ProtoReflect.Descriptor instead.
func (*InferResponseHeader_Output_Class) Descriptor() ([]byte, []int) {
	return file_api_proto_rawDescGZIP(), []int{2, 0, 1}
}

func (x *InferResponseHeader_Output_Class) GetIdx() int32 {
	if x != nil {
		return x.Idx
	}
	return 0
}

func (x *InferResponseHeader_Output_Class) GetValue() float32 {
	if x != nil {
		return x.Value
	}
	return 0
}

func (x *InferResponseHeader_Output_Class) GetLabel() string {
	if x != nil {
		return x.Label
	}
	return ""
}

//@@    .. cpp:var:: message Classes
//@@
//@@       Meta-data for an output tensor being returned as classifications.
//@@
type InferResponseHeader_Output_Classes struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	//@@      .. cpp:var:: Class cls (repeated)
	//@@
	//@@         The topk classes for this output.
	//@@
	Cls []*InferResponseHeader_Output_Class `protobuf:"bytes,1,rep,name=cls,proto3" json:"cls,omitempty"`
}

func (x *InferResponseHeader_Output_Classes) Reset() {
	*x = InferResponseHeader_Output_Classes{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_proto_msgTypes[9]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *InferResponseHeader_Output_Classes) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferResponseHeader_Output_Classes) ProtoMessage() {}

func (x *InferResponseHeader_Output_Classes) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_msgTypes[9]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferResponseHeader_Output_Classes.ProtoReflect.Descriptor instead.
func (*InferResponseHeader_Output_Classes) Descriptor() ([]byte, []int) {
	return file_api_proto_rawDescGZIP(), []int{2, 0, 2}
}

func (x *InferResponseHeader_Output_Classes) GetCls() []*InferResponseHeader_Output_Class {
	if x != nil {
		return x.Cls
	}
	return nil
}

var File_api_proto protoreflect.FileDescriptor

var file_api_proto_rawDesc = []byte{
	0x0a, 0x09, 0x61, 0x70, 0x69, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x12, 0x16, 0x6e, 0x76, 0x69,
	0x64, 0x69, 0x61, 0x2e, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e, 0x63, 0x65, 0x73, 0x65, 0x72,
	0x76, 0x65, 0x72, 0x1a, 0x12, 0x6d, 0x6f, 0x64, 0x65, 0x6c, 0x5f, 0x63, 0x6f, 0x6e, 0x66, 0x69,
	0x67, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22, 0x5c, 0x0a, 0x11, 0x49, 0x6e, 0x66, 0x65, 0x72,
	0x53, 0x68, 0x61, 0x72, 0x65, 0x64, 0x4d, 0x65, 0x6d, 0x6f, 0x72, 0x79, 0x12, 0x12, 0x0a, 0x04,
	0x6e, 0x61, 0x6d, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x6e, 0x61, 0x6d, 0x65,
	0x12, 0x16, 0x0a, 0x06, 0x6f, 0x66, 0x66, 0x73, 0x65, 0x74, 0x18, 0x02, 0x20, 0x01, 0x28, 0x04,
	0x52, 0x06, 0x6f, 0x66, 0x66, 0x73, 0x65, 0x74, 0x12, 0x1b, 0x0a, 0x09, 0x62, 0x79, 0x74, 0x65,
	0x5f, 0x73, 0x69, 0x7a, 0x65, 0x18, 0x03, 0x20, 0x01, 0x28, 0x04, 0x52, 0x08, 0x62, 0x79, 0x74,
	0x65, 0x53, 0x69, 0x7a, 0x65, 0x22, 0xac, 0x06, 0x0a, 0x12, 0x49, 0x6e, 0x66, 0x65, 0x72, 0x52,
	0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x48, 0x65, 0x61, 0x64, 0x65, 0x72, 0x12, 0x0e, 0x0a, 0x02,
	0x69, 0x64, 0x18, 0x05, 0x20, 0x01, 0x28, 0x04, 0x52, 0x02, 0x69, 0x64, 0x12, 0x14, 0x0a, 0x05,
	0x66, 0x6c, 0x61, 0x67, 0x73, 0x18, 0x06, 0x20, 0x01, 0x28, 0x0d, 0x52, 0x05, 0x66, 0x6c, 0x61,
	0x67, 0x73, 0x12, 0x25, 0x0a, 0x0e, 0x63, 0x6f, 0x72, 0x72, 0x65, 0x6c, 0x61, 0x74, 0x69, 0x6f,
	0x6e, 0x5f, 0x69, 0x64, 0x18, 0x04, 0x20, 0x01, 0x28, 0x04, 0x52, 0x0d, 0x63, 0x6f, 0x72, 0x72,
	0x65, 0x6c, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x49, 0x64, 0x12, 0x1d, 0x0a, 0x0a, 0x62, 0x61, 0x74,
	0x63, 0x68, 0x5f, 0x73, 0x69, 0x7a, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0d, 0x52, 0x09, 0x62,
	0x61, 0x74, 0x63, 0x68, 0x53, 0x69, 0x7a, 0x65, 0x12, 0x46, 0x0a, 0x05, 0x69, 0x6e, 0x70, 0x75,
	0x74, 0x18, 0x02, 0x20, 0x03, 0x28, 0x0b, 0x32, 0x30, 0x2e, 0x6e, 0x76, 0x69, 0x64, 0x69, 0x61,
	0x2e, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e, 0x63, 0x65, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72,
	0x2e, 0x49, 0x6e, 0x66, 0x65, 0x72, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x48, 0x65, 0x61,
	0x64, 0x65, 0x72, 0x2e, 0x49, 0x6e, 0x70, 0x75, 0x74, 0x52, 0x05, 0x69, 0x6e, 0x70, 0x75, 0x74,
	0x12, 0x49, 0x0a, 0x06, 0x6f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x18, 0x03, 0x20, 0x03, 0x28, 0x0b,
	0x32, 0x31, 0x2e, 0x6e, 0x76, 0x69, 0x64, 0x69, 0x61, 0x2e, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65,
	0x6e, 0x63, 0x65, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x49, 0x6e, 0x66, 0x65, 0x72, 0x52,
	0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x48, 0x65, 0x61, 0x64, 0x65, 0x72, 0x2e, 0x4f, 0x75, 0x74,
	0x70, 0x75, 0x74, 0x52, 0x06, 0x6f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x12, 0x1a, 0x0a, 0x08, 0x70,
	0x72, 0x69, 0x6f, 0x72, 0x69, 0x74, 0x79, 0x18, 0x07, 0x20, 0x01, 0x28, 0x0d, 0x52, 0x08, 0x70,
	0x72, 0x69, 0x6f, 0x72, 0x69, 0x74, 0x79, 0x12, 0x31, 0x0a, 0x14, 0x74, 0x69, 0x6d, 0x65, 0x6f,
	0x75, 0x74, 0x5f, 0x6d, 0x69, 0x63, 0x72, 0x6f, 0x73, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x73, 0x18,
	0x08, 0x20, 0x01, 0x28, 0x04, 0x52, 0x13, 0x74, 0x69, 0x6d, 0x65, 0x6f, 0x75, 0x74, 0x4d, 0x69,
	0x63, 0x72, 0x6f, 0x73, 0x65, 0x63, 0x6f, 0x6e, 0x64, 0x73, 0x1a, 0xa7, 0x01, 0x0a, 0x05, 0x49,
	0x6e, 0x70, 0x75, 0x74, 0x12, 0x12, 0x0a, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x01, 0x20, 0x01,
	0x28, 0x09, 0x52, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x12, 0x12, 0x0a, 0x04, 0x64, 0x69, 0x6d, 0x73,
	0x18, 0x02, 0x20, 0x03, 0x28, 0x03, 0x52, 0x04, 0x64, 0x69, 0x6d, 0x73, 0x12, 0x26, 0x0a, 0x0f,
	0x62, 0x61, 0x74, 0x63, 0x68, 0x5f, 0x62, 0x79, 0x74, 0x65, 0x5f, 0x73, 0x69, 0x7a, 0x65, 0x18,
	0x03, 0x20, 0x01, 0x28, 0x04, 0x52, 0x0d, 0x62, 0x61, 0x74, 0x63, 0x68, 0x42, 0x79, 0x74, 0x65,
	0x53, 0x69, 0x7a, 0x65, 0x12, 0x4e, 0x0a, 0x0d, 0x73, 0x68, 0x61, 0x72, 0x65, 0x64, 0x5f, 0x6d,
	0x65, 0x6d, 0x6f, 0x72, 0x79, 0x18, 0x04, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x29, 0x2e, 0x6e, 0x76,
	0x69, 0x64, 0x69, 0x61, 0x2e, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e, 0x63, 0x65, 0x73, 0x65,
	0x72, 0x76, 0x65, 0x72, 0x2e, 0x49, 0x6e, 0x66, 0x65, 0x72, 0x53, 0x68, 0x61, 0x72, 0x65, 0x64,
	0x4d, 0x65, 0x6d, 0x6f, 0x72, 0x79, 0x52, 0x0c, 0x73, 0x68, 0x61, 0x72, 0x65, 0x64, 0x4d, 0x65,
	0x6d, 0x6f, 0x72, 0x79, 0x1a, 0xd6, 0x01, 0x0a, 0x06, 0x4f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x12,
	0x12, 0x0a, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x6e,
	0x61, 0x6d, 0x65, 0x12, 0x49, 0x0a, 0x03, 0x63, 0x6c, 0x73, 0x18, 0x03, 0x20, 0x01, 0x28, 0x0b,
	0x32, 0x37, 0x2e, 0x6e, 0x76, 0x69, 0x64, 0x69, 0x61, 0x2e, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65,
	0x6e, 0x63, 0x65, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x49, 0x6e, 0x66, 0x65, 0x72, 0x52,
	0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x48, 0x65, 0x61, 0x64, 0x65, 0x72, 0x2e, 0x4f, 0x75, 0x74,
	0x70, 0x75, 0x74, 0x2e, 0x43, 0x6c, 0x61, 0x73, 0x73, 0x52, 0x03, 0x63, 0x6c, 0x73, 0x12, 0x4e,
	0x0a, 0x0d, 0x73, 0x68, 0x61, 0x72, 0x65, 0x64, 0x5f, 0x6d, 0x65, 0x6d, 0x6f, 0x72, 0x79, 0x18,
	0x04, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x29, 0x2e, 0x6e, 0x76, 0x69, 0x64, 0x69, 0x61, 0x2e, 0x69,
	0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e, 0x63, 0x65, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x49,
	0x6e, 0x66, 0x65, 0x72, 0x53, 0x68, 0x61, 0x72, 0x65, 0x64, 0x4d, 0x65, 0x6d, 0x6f, 0x72, 0x79,
	0x52, 0x0c, 0x73, 0x68, 0x61, 0x72, 0x65, 0x64, 0x4d, 0x65, 0x6d, 0x6f, 0x72, 0x79, 0x1a, 0x1d,
	0x0a, 0x05, 0x43, 0x6c, 0x61, 0x73, 0x73, 0x12, 0x14, 0x0a, 0x05, 0x63, 0x6f, 0x75, 0x6e, 0x74,
	0x18, 0x01, 0x20, 0x01, 0x28, 0x0d, 0x52, 0x05, 0x63, 0x6f, 0x75, 0x6e, 0x74, 0x22, 0x45, 0x0a,
	0x04, 0x46, 0x6c, 0x61, 0x67, 0x12, 0x0d, 0x0a, 0x09, 0x46, 0x4c, 0x41, 0x47, 0x5f, 0x4e, 0x4f,
	0x4e, 0x45, 0x10, 0x00, 0x12, 0x17, 0x0a, 0x13, 0x46, 0x4c, 0x41, 0x47, 0x5f, 0x53, 0x45, 0x51,
	0x55, 0x45, 0x4e, 0x43, 0x45, 0x5f, 0x53, 0x54, 0x41, 0x52, 0x54, 0x10, 0x01, 0x12, 0x15, 0x0a,
	0x11, 0x46, 0x4c, 0x41, 0x47, 0x5f, 0x53, 0x45, 0x51, 0x55, 0x45, 0x4e, 0x43, 0x45, 0x5f, 0x45,
	0x4e, 0x44, 0x10, 0x02, 0x22, 0xbe, 0x05, 0x0a, 0x13, 0x49, 0x6e, 0x66, 0x65, 0x72, 0x52, 0x65,
	0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x48, 0x65, 0x61, 0x64, 0x65, 0x72, 0x12, 0x0e, 0x0a, 0x02,
	0x69, 0x64, 0x18, 0x05, 0x20, 0x01, 0x28, 0x04, 0x52, 0x02, 0x69, 0x64, 0x12, 0x1d, 0x0a, 0x0a,
	0x6d, 0x6f, 0x64, 0x65, 0x6c, 0x5f, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09,
	0x52, 0x09, 0x6d, 0x6f, 0x64, 0x65, 0x6c, 0x4e, 0x61, 0x6d, 0x65, 0x12, 0x23, 0x0a, 0x0d, 0x6d,
	0x6f, 0x64, 0x65, 0x6c, 0x5f, 0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x18, 0x02, 0x20, 0x01,
	0x28, 0x03, 0x52, 0x0c, 0x6d, 0x6f, 0x64, 0x65, 0x6c, 0x56, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e,
	0x12, 0x1d, 0x0a, 0x0a, 0x62, 0x61, 0x74, 0x63, 0x68, 0x5f, 0x73, 0x69, 0x7a, 0x65, 0x18, 0x03,
	0x20, 0x01, 0x28, 0x0d, 0x52, 0x09, 0x62, 0x61, 0x74, 0x63, 0x68, 0x53, 0x69, 0x7a, 0x65, 0x12,
	0x4a, 0x0a, 0x06, 0x6f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x18, 0x04, 0x20, 0x03, 0x28, 0x0b, 0x32,
	0x32, 0x2e, 0x6e, 0x76, 0x69, 0x64, 0x69, 0x61, 0x2e, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e,
	0x63, 0x65, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x49, 0x6e, 0x66, 0x65, 0x72, 0x52, 0x65,
	0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x48, 0x65, 0x61, 0x64, 0x65, 0x72, 0x2e, 0x4f, 0x75, 0x74,
	0x70, 0x75, 0x74, 0x52, 0x06, 0x6f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x1a, 0xe7, 0x03, 0x0a, 0x06,
	0x4f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x12, 0x12, 0x0a, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x01,
	0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x12, 0x3d, 0x0a, 0x09, 0x64, 0x61,
	0x74, 0x61, 0x5f, 0x74, 0x79, 0x70, 0x65, 0x18, 0x04, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x20, 0x2e,
	0x6e, 0x76, 0x69, 0x64, 0x69, 0x61, 0x2e, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e, 0x63, 0x65,
	0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x44, 0x61, 0x74, 0x61, 0x54, 0x79, 0x70, 0x65, 0x52,
	0x08, 0x64, 0x61, 0x74, 0x61, 0x54, 0x79, 0x70, 0x65, 0x12, 0x48, 0x0a, 0x03, 0x72, 0x61, 0x77,
	0x18, 0x02, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x36, 0x2e, 0x6e, 0x76, 0x69, 0x64, 0x69, 0x61, 0x2e,
	0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e, 0x63, 0x65, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e,
	0x49, 0x6e, 0x66, 0x65, 0x72, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x48, 0x65, 0x61,
	0x64, 0x65, 0x72, 0x2e, 0x4f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x2e, 0x52, 0x61, 0x77, 0x52, 0x03,
	0x72, 0x61, 0x77, 0x12, 0x5f, 0x0a, 0x0d, 0x62, 0x61, 0x74, 0x63, 0x68, 0x5f, 0x63, 0x6c, 0x61,
	0x73, 0x73, 0x65, 0x73, 0x18, 0x03, 0x20, 0x03, 0x28, 0x0b, 0x32, 0x3a, 0x2e, 0x6e, 0x76, 0x69,
	0x64, 0x69, 0x61, 0x2e, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e, 0x63, 0x65, 0x73, 0x65, 0x72,
	0x76, 0x65, 0x72, 0x2e, 0x49, 0x6e, 0x66, 0x65, 0x72, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73,
	0x65, 0x48, 0x65, 0x61, 0x64, 0x65, 0x72, 0x2e, 0x4f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x2e, 0x43,
	0x6c, 0x61, 0x73, 0x73, 0x65, 0x73, 0x52, 0x0c, 0x62, 0x61, 0x74, 0x63, 0x68, 0x43, 0x6c, 0x61,
	0x73, 0x73, 0x65, 0x73, 0x1a, 0x41, 0x0a, 0x03, 0x52, 0x61, 0x77, 0x12, 0x12, 0x0a, 0x04, 0x64,
	0x69, 0x6d, 0x73, 0x18, 0x01, 0x20, 0x03, 0x28, 0x03, 0x52, 0x04, 0x64, 0x69, 0x6d, 0x73, 0x12,
	0x26, 0x0a, 0x0f, 0x62, 0x61, 0x74, 0x63, 0x68, 0x5f, 0x62, 0x79, 0x74, 0x65, 0x5f, 0x73, 0x69,
	0x7a, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28, 0x04, 0x52, 0x0d, 0x62, 0x61, 0x74, 0x63, 0x68, 0x42,
	0x79, 0x74, 0x65, 0x53, 0x69, 0x7a, 0x65, 0x1a, 0x45, 0x0a, 0x05, 0x43, 0x6c, 0x61, 0x73, 0x73,
	0x12, 0x10, 0x0a, 0x03, 0x69, 0x64, 0x78, 0x18, 0x01, 0x20, 0x01, 0x28, 0x05, 0x52, 0x03, 0x69,
	0x64, 0x78, 0x12, 0x14, 0x0a, 0x05, 0x76, 0x61, 0x6c, 0x75, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28,
	0x02, 0x52, 0x05, 0x76, 0x61, 0x6c, 0x75, 0x65, 0x12, 0x14, 0x0a, 0x05, 0x6c, 0x61, 0x62, 0x65,
	0x6c, 0x18, 0x03, 0x20, 0x01, 0x28, 0x09, 0x52, 0x05, 0x6c, 0x61, 0x62, 0x65, 0x6c, 0x1a, 0x55,
	0x0a, 0x07, 0x43, 0x6c, 0x61, 0x73, 0x73, 0x65, 0x73, 0x12, 0x4a, 0x0a, 0x03, 0x63, 0x6c, 0x73,
	0x18, 0x01, 0x20, 0x03, 0x28, 0x0b, 0x32, 0x38, 0x2e, 0x6e, 0x76, 0x69, 0x64, 0x69, 0x61, 0x2e,
	0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e, 0x63, 0x65, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e,
	0x49, 0x6e, 0x66, 0x65, 0x72, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x48, 0x65, 0x61,
	0x64, 0x65, 0x72, 0x2e, 0x4f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x2e, 0x43, 0x6c, 0x61, 0x73, 0x73,
	0x52, 0x03, 0x63, 0x6c, 0x73, 0x62, 0x06, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33,
}

var (
	file_api_proto_rawDescOnce sync.Once
	file_api_proto_rawDescData = file_api_proto_rawDesc
)

func file_api_proto_rawDescGZIP() []byte {
	file_api_proto_rawDescOnce.Do(func() {
		file_api_proto_rawDescData = protoimpl.X.CompressGZIP(file_api_proto_rawDescData)
	})
	return file_api_proto_rawDescData
}

var file_api_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_api_proto_msgTypes = make([]protoimpl.MessageInfo, 10)
var file_api_proto_goTypes = []interface{}{
	(InferRequestHeader_Flag)(0),               // 0: nvidia.inferenceserver.InferRequestHeader.Flag
	(*InferSharedMemory)(nil),                  // 1: nvidia.inferenceserver.InferSharedMemory
	(*InferRequestHeader)(nil),                 // 2: nvidia.inferenceserver.InferRequestHeader
	(*InferResponseHeader)(nil),                // 3: nvidia.inferenceserver.InferResponseHeader
	(*InferRequestHeader_Input)(nil),           // 4: nvidia.inferenceserver.InferRequestHeader.Input
	(*InferRequestHeader_Output)(nil),          // 5: nvidia.inferenceserver.InferRequestHeader.Output
	(*InferRequestHeader_Output_Class)(nil),    // 6: nvidia.inferenceserver.InferRequestHeader.Output.Class
	(*InferResponseHeader_Output)(nil),         // 7: nvidia.inferenceserver.InferResponseHeader.Output
	(*InferResponseHeader_Output_Raw)(nil),     // 8: nvidia.inferenceserver.InferResponseHeader.Output.Raw
	(*InferResponseHeader_Output_Class)(nil),   // 9: nvidia.inferenceserver.InferResponseHeader.Output.Class
	(*InferResponseHeader_Output_Classes)(nil), // 10: nvidia.inferenceserver.InferResponseHeader.Output.Classes
	(DataType)(0), // 11: nvidia.inferenceserver.DataType
}
var file_api_proto_depIdxs = []int32{
	4,  // 0: nvidia.inferenceserver.InferRequestHeader.input:type_name -> nvidia.inferenceserver.InferRequestHeader.Input
	5,  // 1: nvidia.inferenceserver.InferRequestHeader.output:type_name -> nvidia.inferenceserver.InferRequestHeader.Output
	7,  // 2: nvidia.inferenceserver.InferResponseHeader.output:type_name -> nvidia.inferenceserver.InferResponseHeader.Output
	1,  // 3: nvidia.inferenceserver.InferRequestHeader.Input.shared_memory:type_name -> nvidia.inferenceserver.InferSharedMemory
	6,  // 4: nvidia.inferenceserver.InferRequestHeader.Output.cls:type_name -> nvidia.inferenceserver.InferRequestHeader.Output.Class
	1,  // 5: nvidia.inferenceserver.InferRequestHeader.Output.shared_memory:type_name -> nvidia.inferenceserver.InferSharedMemory
	11, // 6: nvidia.inferenceserver.InferResponseHeader.Output.data_type:type_name -> nvidia.inferenceserver.DataType
	8,  // 7: nvidia.inferenceserver.InferResponseHeader.Output.raw:type_name -> nvidia.inferenceserver.InferResponseHeader.Output.Raw
	10, // 8: nvidia.inferenceserver.InferResponseHeader.Output.batch_classes:type_name -> nvidia.inferenceserver.InferResponseHeader.Output.Classes
	9,  // 9: nvidia.inferenceserver.InferResponseHeader.Output.Classes.cls:type_name -> nvidia.inferenceserver.InferResponseHeader.Output.Class
	10, // [10:10] is the sub-list for method output_type
	10, // [10:10] is the sub-list for method input_type
	10, // [10:10] is the sub-list for extension type_name
	10, // [10:10] is the sub-list for extension extendee
	0,  // [0:10] is the sub-list for field type_name
}

func init() { file_api_proto_init() }
func file_api_proto_init() {
	if File_api_proto != nil {
		return
	}
	file_model_config_proto_init()
	if !protoimpl.UnsafeEnabled {
		file_api_proto_msgTypes[0].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*InferSharedMemory); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_proto_msgTypes[1].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*InferRequestHeader); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_proto_msgTypes[2].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*InferResponseHeader); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_proto_msgTypes[3].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*InferRequestHeader_Input); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_proto_msgTypes[4].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*InferRequestHeader_Output); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_proto_msgTypes[5].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*InferRequestHeader_Output_Class); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_proto_msgTypes[6].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*InferResponseHeader_Output); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_proto_msgTypes[7].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*InferResponseHeader_Output_Raw); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_proto_msgTypes[8].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*InferResponseHeader_Output_Class); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_proto_msgTypes[9].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*InferResponseHeader_Output_Classes); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: file_api_proto_rawDesc,
			NumEnums:      1,
			NumMessages:   10,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_api_proto_goTypes,
		DependencyIndexes: file_api_proto_depIdxs,
		EnumInfos:         file_api_proto_enumTypes,
		MessageInfos:      file_api_proto_msgTypes,
	}.Build()
	File_api_proto = out.File
	file_api_proto_rawDesc = nil
	file_api_proto_goTypes = nil
	file_api_proto_depIdxs = nil
}
